{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import string\n",
    "import seaborn as sns\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "import matplotlib.colors as cl\n",
    "import glob\n",
    "from cryodrgn import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following cells produces a dataframe in which each row contains the occupancy data for one of the maps sampled from latent space, and each column corresponds to the occupancy of a given subunit across maps, normalized by the reference volume. Change the variables in the first box as necessary to reflect the path where your occupancies.csv file from the calc_occupancy.py script is located.\n",
    "\n",
    "This notebook can also be used for datasets other than EMPIAR 10076; simply change the number of volumes as necessary, and redefine the chains dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this to wherever your experimental map occupancy table is stored\n",
    "occupancies = #FILL ME IN\n",
    "\n",
    "#change these as necessary for different numbers of volumes or different PDB models\n",
    "num_volumes = 500\n",
    "\n",
    "chains = {}\n",
    "chains['prots1'] = ['L2', 'L3', 'L4', 'L5', 'L6', 'L9', 'L11', 'L13'] + ['L' + str(i) for i in range(14,26)] + ['L27', 'L28', 'L29', 'L30', 'L32', 'L33']\n",
    "chains['prots2'] = ['L34', 'L35', 'L36']\n",
    "chains['RNA1'] = ['H' + str(i) for i in range(1,15)] + ['H16'] + ['H' + str(i) for i in range(18,26)] + ['H25a', 'H26', 'H27']\n",
    "chains['RNA2'] = ['H28', 'H29'] + ['H' + str(i) for i in range(31,36)] + ['H35a'] + ['H' + str(i) for i in range(36,47)] + ['H26a', 'H47', 'H48', 'H49', 'H49b', 'H50', 'H51']\n",
    "chains['RNA3'] = ['H52', 'H53', 'H54', 'H55', 'H49a'] + ['H' + str(i) for i in range(56,70)] + ['H' + str(i) for i in range(71,78)] \n",
    "chains['RNA4'] = ['H' + str(i) for i in range(78,102)]\n",
    "chains['RNA_5S'] = ['H' + str(i) + '_5S' for i in range(1,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(occupancies, index_col = 0, header = [0,1]).dropna(axis = 1)\n",
    "df_rename = pd.DataFrame(index = df.index)\n",
    "alpha_list = string.ascii_lowercase\n",
    "\n",
    "for col in df.columns:\n",
    "    pdb_name, chain = col\n",
    "    chain_ind = alpha_list.index(chain)\n",
    "    chain_id = chains[pdb_name][chain_ind]\n",
    "    \n",
    "    df_rename[chain_id] = df[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization methods may vary on a dataset-by-dataset basis. We implement here a method that effectively rescales all the occupancies so they fall between what we consider zero occupancy and what we consider full occupancy. These designations of zero and complete occupancy are determined as percentiles of the full set of values from df_rename. For this dataset, we recommend using the 10th and 90th percentiles as zero and full occupancies, respectively, but again this may differ for other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this to alter the percentile of the data to be set as zero occupancy\n",
    "low_cutoff = 10\n",
    "\n",
    "#change this to alter the  percentile of the data to be set as full occupancy\n",
    "high_cutoff = 90\n",
    "\n",
    "#change this to indicate the directory where you want the output dataframe stored\n",
    "outdir = './'#FILL ME IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = df_rename.values.flatten()\n",
    "q_low = np.percentile(vals, low_cutoff)\n",
    "q_high = np.percentile(vals, high_cutoff)\n",
    "\n",
    "df_rename[df_rename < q_low] = q_low\n",
    "df_rename[df_rename > q_high] = q_high\n",
    "\n",
    "for col in df_rename.columns:\n",
    "    df_rename[col] = (df_rename[col]-q_low)/(q_high-q_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save output .txt file\n",
    "df_rename.to_csv(outdir + 'norm_occs.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical clustering can be performed either directly in python with the code below, or in an external interactive clustering program using the output dataframe .csv files. The code below returns the nodes for the rows and columns separately; these outputs are parsed in the next sections to automatically extract volume classes and structural blocks, and to write scripts to visualize the blocks and volumes in ChimeraX. Adjusting the linkage method or distance metric may change the results of the clustering. Given a single clustering result, changing the row or column threshold adjusts the threshold distance at which classes are defined. Changing the default save_file variable to a path will save the resulting figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define clustering choices\n",
    "figsize= #FILL ME IN\n",
    "row_threshold= #FILL ME IN\n",
    "col_threshold= #FILL ME IN\n",
    "linkage_methods = 'ward'\n",
    "distance_metric = 'euclidean'\n",
    "cmap='Blues'\n",
    "row_cmap = 'Spectral'\n",
    "col_cmap = 'viridis'\n",
    "save_file = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_occupancy(data, linkage_method='ward', distance_metric='euclidean', figsize=(10,10), cmap='Blues', row_threshold=-1, col_threshold=-1, row_map = 'Spectral', col_map = 'viridis', save_file = None):\n",
    "    \n",
    "    \n",
    "    col_linkage = hierarchy.linkage(distance.pdist(data.T, metric=distance_metric), method=linkage_methods)\n",
    "    row_linkage = hierarchy.linkage(distance.pdist(data, metric=distance_metric), method=linkage_methods)\n",
    "    row_total = np.max(hierarchy.fcluster(row_linkage, t = row_threshold, criterion = 'distance'))\n",
    "    col_total = np.max(hierarchy.fcluster(col_linkage, t = col_threshold, criterion = 'distance'))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, gridspec_kw={'width_ratios': [1, 4], 'height_ratios': [1,4]}, figsize=figsize)\n",
    "    \n",
    "    row_map = plt.matplotlib.cm.get_cmap(row_map)\n",
    "    col_map = plt.matplotlib.cm.get_cmap(col_map)\n",
    "    row_colors = [cl.rgb2hex(row_map(i/row_total)) for i in range(0, row_total)]\n",
    "    col_colors = [cl.rgb2hex(col_map(i/col_total)) for i in range(0, row_total)]\n",
    "    hierarchy.set_link_color_palette(col_colors)\n",
    "    \n",
    "    col_nodes = hierarchy.dendrogram(col_linkage, color_threshold=col_threshold, ax = axes[0][1], get_leaves=True, labels=data.columns.tolist(), above_threshold_color = 'black')\n",
    "    axes[0][1].axhline(col_threshold, ls='dashed', color='grey')\n",
    "    axes[0][1].spines['top'].set_visible(False)\n",
    "    axes[0][1].spines['right'].set_visible(False)\n",
    "    axes[0][1].spines['bottom'].set_visible(False)\n",
    "    \n",
    "    hierarchy.set_link_color_palette(row_colors)\n",
    "    row_nodes = hierarchy.dendrogram(row_linkage, color_threshold=row_threshold, ax = axes[1][0], orientation='left', get_leaves=True, labels=data.index.tolist(), above_threshold_color = 'black')\n",
    "    axes[1][0].axvline(row_threshold, ls='dashed', color='grey')\n",
    "    axes[1][0].spines['top'].set_visible(False)\n",
    "    axes[1][0].spines['right'].set_visible(False)\n",
    "    axes[1][0].spines['left'].set_visible(False)\n",
    "    \n",
    "    data_ordered=data[[data.columns[i] for i in col_nodes['leaves']]]\n",
    "    \n",
    "    data_ordered = data_ordered.reindex(data.index[row_nodes['leaves']])\n",
    "    heatmap = axes[1][1].pcolor(data_ordered, cmap=cmap)\n",
    "    axes[1][1].set_xticks([])\n",
    "    axes[1][1].set_yticks([])\n",
    "    \n",
    "    fig.colorbar(heatmap, ax=axes[0][0], fraction=0.75, label='occupancy')\n",
    "    axes[0][0].set_xticks([])\n",
    "    axes[0][0].set_yticks([])\n",
    "    axes[0][0].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_file:\n",
    "        fig.savefig(save_file)\n",
    "    \n",
    "    return (row_nodes, col_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_nodes, col_nodes = plot_occupancy(df_rename, row_threshold=row_threshold, col_threshold=col_threshold, figsize=figsize, row_map = row_cmap, col_map = col_cmap, linkage_method = linkage_methods, distance_metric = distance_metric, save_file = save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract classes from clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the volume and subunit classes defined in the clustering above can be extracted for manual inspection and for mapping into latent space and finding centroid volumes. Here we create two dictionaries with a common set of keys for each of row_nodes and col_nodes. The keys are the class/structural block IDs, and the values of the colors_dict and groups_dict dictionaries indicate the color (as a hexadecimal string) of each cluster in the above dendrogram, and the rows or columns that belong to that class, respectively.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_groups(nodes):\n",
    "    colors, color_inds = np.unique(nodes['leaves_color_list'], return_index = True)\n",
    "    color_groupings = [np.where(np.array(nodes['leaves_color_list']) == i)[0] for i in colors]\n",
    "    ind_groupings = [np.array(nodes['ivl'])[i] for i in color_groupings]\n",
    "    \n",
    "    groups_dict = {}\n",
    "    colors_dict = {}\n",
    "    for i in range(0, len(colors)):\n",
    "        col = nodes['leaves_color_list'][np.sort(color_inds)[::-1][i]]\n",
    "        colors_dict[i] = col\n",
    "        ind = np.where(colors == col)[0][0]\n",
    "        groups_dict[i] = ind_groupings[ind]\n",
    "    return colors_dict, groups_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_colors, vol_classes = extract_groups(row_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subunit_colors, subunit_blocks = extract_groups(col_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_pkl(vol_classes, 'vol_classes.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize volume classes in ChimeraX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each volume class defined above, this section writes out a .py script that can be opened in ChimeraX. Each script will open all the volumes from the given class so they can be manually compared. Note that the full path of the directory containing the 500 sampled maps must be provided in the vol_dir variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_dir = #FILL ME IN\n",
    "out_dir = #FILL ME IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dir(dirname, make = True):\n",
    "    if make:\n",
    "        if not os.path.exists(dirname):\n",
    "            os.mkdir(dirname)\n",
    "    if not dirname.endswith('/'):\n",
    "        dirname = dirname + '/'\n",
    "    return dirname\n",
    "        \n",
    "def write_vol_classes(groups_dict, voldir, outdir):\n",
    "    voldir = check_dir(voldir, make = False)\n",
    "    outdir = check_dir(outdir)\n",
    "            \n",
    "    for i in groups_dict.keys():\n",
    "        outfile = outdir + 'class' + str(i) + '.py'\n",
    "        with open(outfile, 'w') as f:\n",
    "            f.write('from chimerax.core.commands import run\\n')\n",
    "            for j in groups_dict[i]:\n",
    "                f.write('run(session, \"open {}vol_{:03d}.mrc\")\\n'.format(voldir, j))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_vol_classes(vol_classes, vol_dir, out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize structural blocks in ChimeraX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also write out a single script to open the aligned PDB files and color each chain according to the structural block assigned in clustering. This script can then be opened with ChimeraX. Note that the full path of the directory containing the aligned files must be provided in the aligned_dir variable, and that the only PDB files in that directory should be the aligned files you want to color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_dir = #FILL ME IN \n",
    "out_file = #FILL ME IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_subunit_blocks(groups_dict, colors_dict, aligneddir, outfile):\n",
    "    aligneddir = check_dir(aligneddir, make = False)\n",
    "    pdb_list = glob.glob(aligneddir + '*.pdb')\n",
    "    alpha_list = list(string.ascii_uppercase)\n",
    "    command_list = []\n",
    "    for i in groups_dict.keys():\n",
    "        command = 'run(session, \"color '\n",
    "        for j in groups_dict[i]:\n",
    "            pdb_file = [k for k in chains.keys() if j in chains[k]][0]\n",
    "            pdb_ind = pdb_list.index(aligneddir + pdb_file + '.pdb') + 1\n",
    "            chain = alpha_list[chains[pdb_file].index(j)]\n",
    "            command = command + f'#{pdb_ind}/{chain} '\n",
    "        command = command + f'{colors_dict[i]}\")\\n'\n",
    "        command_list.append(command)    \n",
    "    \n",
    "    with open(outfile, 'w') as f:\n",
    "        f.write('from chimerax.core.commands import  run \\n')\n",
    "        for pdb in pdb_list:\n",
    "            f.write(f'run(session, \"open {pdb}\")\\n')\n",
    "        for com in command_list:\n",
    "            f.write(com)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_subunit_blocks(subunit_blocks, subunit_colors, aligned_dir, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot individual subunit occupancy distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the occupancy distributions of a set of subunits, users can provide a list of subunits (or a whole subunit block from the subunit_blocks dictionary) to the plot_distribution function. To log-scale the y-axis of the figure, set log_plot = True. To overlay a dashed line indicating a particular subunit occupancy, provide a dictionary whose keys are the subunits being plotted and whose values are the desired values, e.g. threshold_dict['H68'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subunits = #FILL ME IN\n",
    "log_plot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(data, subs, color = 'steelblue', log = False):\n",
    "    nrows = int(np.ceil(len(subs)/3))\n",
    "    figsize = (8, 2*nrows)\n",
    "    fig, ax = plt.subplots(nrows, 3, figsize = figsize, sharex = True, sharey = True)\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    bins = np.linspace(0, 1, 25)\n",
    "    for i,sub in enumerate(subs):\n",
    "        ax[i].hist(data[sub], bins = bins, color = color, log = log)\n",
    "        ax[i].set_title(sub)\n",
    "        if thresholds:\n",
    "            upper_lim = y_hist.max()\n",
    "            ax[i].plot([thresholds[sub], thresholds[sub]], [0, upper_lim], '--k')\n",
    "            \n",
    "    if len(subs)%3 > 0:\n",
    "        fig.delaxes(ax[i+1])\n",
    "        if len(subs)%3 == 1:\n",
    "            fig.delaxes(ax[i+2])\n",
    "\n",
    "    fig.text(0.5, 0, 'occupancy')\n",
    "    fig.text(0, 0.5, 'counts', rotation = 90)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if outfile:\n",
    "        plt.savefig(outfile, dpi = 300)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df_rename, subunits, log = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine subunit-subunit correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting subunit-subunit correlation can be informative for determining if there is positive or negative cooperativity between any two given subunits. Users can here provide a list of subunits to compare, where each subunits[i] is a list of two subunits to be plotted against each other. Overlaid dashed lines can again be implemented by using supplying a thresholds dictionary (as described above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subunits = #FILL ME IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subunit_corr(data, subs, color = 'steelblue', thresholds = None, outfile = None):\n",
    "    \n",
    "    nrows = int(np.ceil(len(subs)/3))\n",
    "    figsize = (8, 2*nrows)\n",
    "    fig, ax = plt.subplots(nrows, 3, figsize = figsize, sharex = True, sharey = True)\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    for i,j in enumerate(subs):\n",
    "        ax[i].scatter(data[j[0]], data[j[1]], color = color, s = 10, alpha = 0.1) \n",
    "        ax[i].set_xlim(-0.05, 1.05)\n",
    "        ax[i].set_ylim(-0.05, 1.05)\n",
    "        ax[i].set_xlabel(j[0])\n",
    "        ax[i].set_ylabel(j[1])\n",
    "        if thresholds:\n",
    "            ax[i].plot([thresholds[j[0]], thresholds[j[0]]], [0, 1], '--k')\n",
    "            ax[i].plot([0, 1], [thresholds[j[1]], thresholds[j[1]]], '--k')\n",
    "    \n",
    "    if len(subs)%3 > 0:\n",
    "        fig.delaxes(ax[i+1])\n",
    "        if len(subs)%3 == 1:\n",
    "            fig.delaxes(ax[i+2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if outfile:\n",
    "        plt.savefig(outfile, dpi = 300)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subunit_corr(df_rename, subunits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recluster subsets of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be useful in some cases to extract and recluster some subset of the volumes that have high (or low) occupancy for a given subunit or subunits. That can be done here by providing a list of subunits to filter by (e.g. ['H68', 'H79']), a list of limits by which to filter each subunit (e.g. [0.5, 0.5]), and then a list of directions for the filtration provided as 'greater' or 'lesser', based on whether you want to retain volumes greater than or less than the limit. The resulting filtered dataframe is then reclustered and the resulting volume classes and structural blocks can be exported to ChimeraX as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define  the subset of the dataframe \n",
    "subunits = #FILL ME IN \n",
    "limits = #FILL ME IN\n",
    "direction = #FILL ME IN \n",
    "\n",
    "#define clustering choices\n",
    "sub_figsize= #FILL ME IN\n",
    "sub_row_threshold= #FILL ME IN\n",
    "sub_col_threshold= #FILL ME IN\n",
    "linkage_methods = 'ward'\n",
    "distance_metric = 'euclidean'\n",
    "cmap='Blues'\n",
    "row_cmap = 'Spectral'\n",
    "col_cmap = 'viridis'\n",
    "sub_save_file = #FILL ME IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if direction[0] == 'greater':\n",
    "    sub_df = df_rename[df_rename[subunits[0]] > limits[0]]\n",
    "else:\n",
    "    sub_df = df_rename[df_rename[subunits[0]] <= limits[0]]\n",
    "for i,sub in enumerate(subunits):\n",
    "    if i > 0:\n",
    "        assert(direction[i] == 'greater' or direction[i] == 'lesser')\n",
    "        if direction[i] == 'greater':\n",
    "            sub_df = sub_df[sub_df[sub] > limits[i]]\n",
    "        else:\n",
    "            sub_df = sub_df[sub_df[sub] <= limits[i]]\n",
    "\n",
    "assert(len(sub_df) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_row_nodes, sub_col_nodes = plot_occupancy(sub_df, row_threshold=sub_row_threshold, col_threshold=sub_col_threshold, figsize=sub_figsize, row_map = row_cmap, col_map = col_cmap, linkage_method = linkage_methods, distance_metric = distance_metric, save_file = sub_save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_vol_colors, sub_vol_classes = extract_groups(sub_row_nodes)\n",
    "sub_subunit_colors, sub_subunit_blocks = extract_groups(sub_col_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_out_dir = #FILL ME IN\n",
    "sub_out_file = #FILL ME IN\n",
    "\n",
    "write_vol_classes(sub_vol_classes, vol_dir, sub_out_dir)\n",
    "write_subunit_blocks(sub_subunit_blocks, sub_subunit_colors, aligned_dir, sub_out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
